{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBlzoa0lD05q"
   },
   "source": [
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value.\n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8mca3GRRd7S",
    "outputId": "3cde944e-2103-4a9c-ad6c-864eaf82c34f"
   },
   "outputs": [],
   "source": [
    "!pip install optuna\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8XEI0s9cD05-",
    "outputId": "0ac972c3-2089-4415-d9c0-e9b67985f2ef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NErYalipD058"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yWgE4mT_D06F",
    "outputId": "fe735759-522e-4764-93c8-57e910dc171b"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/Colab Notebooks/Practicum/car_data.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "a5d0NLHKD06L",
    "outputId": "ef9e6b69-5ba0-4c2d-af03-c6ab152dc90c"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzeWri-aD06V"
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8pWdT8TD06X"
   },
   "source": [
    "#### Converting data type\n",
    "\n",
    "Transform data type strategy:\n",
    "\n",
    "* Int: `Price`, `Power`, `Mileage`, `PostalCode`, `NumberOfPictures`\n",
    "* Datetime: `DateCrawled`, `RegistrationYear`, `RegistrationMonth`, `DateCreated`, `LastSeen`\n",
    "* String: `VehicleType`, `Gearbox`, `Model`, `FuelType`, `Brand`, `NotRepaired`\n",
    "\n",
    "Most of string type columns can be transformed to categorical data. I'll do it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVhwFETAD06a"
   },
   "source": [
    "##### Datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mseIo8Y4D06c"
   },
   "source": [
    "Before converting the datetime type, I'll drop the column of `DateCrawled`, it seems redundant and useless for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "Jc1a6D93D06d"
   },
   "outputs": [],
   "source": [
    "df.drop('DateCrawled', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNJucTumD06f"
   },
   "source": [
    "###### `RegistrationYear`\n",
    "\n",
    "During converting the 'RegistrationYear' column, I found there are abnormal years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uq2x36aPD06g",
    "outputId": "b23ace59-05cd-46a7-a3bd-18da3cd7d470"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RegistrationYear'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boNLnQU_D06h",
    "outputId": "37fea1e8-5c75-4590-ecc8-f5d6871e0116"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registration_mask = (df['RegistrationYear'] < 1900) | (df['RegistrationYear'] > 2016)\n",
    "df[registration_mask]['RegistrationYear'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWGlL0gpD06i"
   },
   "source": [
    "Delete abnormal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xMV0dvxMD06i"
   },
   "outputs": [],
   "source": [
    "df = df[~registration_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tTGJhrND06k"
   },
   "source": [
    "There are two columns 'RegistrationYear' and 'RegistrationMonth', but with the same meaning that to indicate the registration time of the car. I'll combine them together and convert it to datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xskiq2EFD06l"
   },
   "source": [
    "###### `RegistrationMonth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8X23SfcuD06l",
    "outputId": "89f8d989-ccb6-4796-917d-178c27519c11"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RegistrationMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsD7RVJoD06m",
    "outputId": "51e185a1-fa2b-4425-db33-648a436cbaa7"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RegistrationMonth'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHpkl1gnD06o"
   },
   "source": [
    "There are 13 unique month values, from 0 to 12, in the column. In `pandas.Series.dt.month`, the correct month values are from 1 to 12, therefore the value 0 is abnormal.\n",
    "\n",
    "Sicne the count number of 0 is 37220, too many to be deleted. I'll break down the values in month of 0 and randomly allocate them to other month groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hyjBl9neD06o",
    "outputId": "08211c0e-b463-44c3-9406-297ca29a33ca"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_mask = df['RegistrationMonth'] == 0\n",
    "random_months = np.random.randint(1, 13, size=month_mask.sum())\n",
    "df.loc[month_mask, 'RegistrationMonth'] = random_months\n",
    "df['RegistrationMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk24P0ZfD06q",
    "outputId": "d5cd5e24-2351-42b2-b1ce-f62fdc30d737"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RegistrationMonth'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Uk0Fh0sD06r"
   },
   "source": [
    "Combine 'RegistrationYear' and 'RegistrationMonth' and convert to 'datetime'. Then only keep the `RegistrationDate` as the time information column, drop others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "x8oxVtXkD06s",
    "outputId": "c468c11a-09a4-4b39-b3ba-5d9c3879e71c"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['RegistrationDate'] = pd.to_datetime(df['RegistrationYear'] * 10000 + df['RegistrationMonth'] * 100 + 1, format='%Y%m%d').dt.date\n",
    "df['RegistrationDate'] = pd.to_datetime(df['RegistrationYear'] * 10000 + df['RegistrationMonth'] * 100 + 1, format='%Y%m%d')\n",
    "# df['DateCreated'] = pd.to_datetime(df['DateCreated']).dt.date.astype('datetime64[ns]')\n",
    "df['LastSeen'] = pd.to_datetime(df['LastSeen'])\n",
    "df.drop(['RegistrationYear', 'RegistrationMonth', 'DateCreated', 'LastSeen'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsxiMqBxD06w"
   },
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5RNX3E4D06x",
    "outputId": "b08fe8f6-3239-48c7-c15b-ee75374486c4"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSS9agULD06z"
   },
   "source": [
    "There are lots of missing values in 5 columns, and cannot be deleted since the missing values take the significant proportion.\n",
    "\n",
    "It's not hard to fill some missing values rely on other information, such as I could fill the `VehicleType` and `FuelType` by the information of `Model`. However, I'm not sure whether it will reflect the prediction result, for example, when customers are browsing the used car website, they would tend to trust the cars with fully information and ignore the cars with certain blank terms, therefore the cars lack of `Notrepaired` information will less likely be trusted and sold. For this reason, If I fill the missing values by my logistic inference, I might affect the prediction result subjectively.\n",
    "\n",
    "So I will fill the missing values with a simple 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZPESdd3D061",
    "outputId": "01747070-fc03-471a-9385-cad11c2c3d38"
   },
   "outputs": [],
   "source": [
    "df['VehicleType'] = df['VehicleType'].fillna('Unknown')\n",
    "df['Gearbox'] = df['Gearbox'].fillna('Unknown')\n",
    "df['Model'] = df['Model'].fillna('Unknown')\n",
    "df['FuelType'] = df['FuelType'].fillna('Unknown')\n",
    "df['NotRepaired'] = df['NotRepaired'].fillna('Unknown')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_3wLexiD062"
   },
   "source": [
    "#### Check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mr56dCWkD063",
    "outputId": "9c752242-c44b-4fc4-bf76-9b75f49ed164"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2khnAEJdD063",
    "outputId": "34f8a2db-d6ab-4ed9-8a4f-fb6942fa05bc"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5l5u3fqVz35"
   },
   "source": [
    "#### Check abnormal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nOCWzOWQV75Y",
    "outputId": "a8e4db9b-bcfa-4ad3-b9a2-e4a1ddb11560"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Fd3Au9oXzjl"
   },
   "source": [
    "There are abnormal values in all numeric columns:\n",
    "\n",
    "* `Price`: The minimum value is 0, it's abnormal.\n",
    "* `Power`: The horsepower of a car changes by the vehicle displacement. It's between tens and hundreds. So the minimum and maximum values are abnormal.\n",
    "* `Mileage`: Half of entries are the same value which is 150000.\n",
    "* `NumberOfPictures`: All entries equal to 0. This column is useless\n",
    "* `PostalCode`: Some entries have 4 digits, while most of the entries have 5 digits.\n",
    "\n",
    "I don't have any other information to deal with `Mileage`, it's too many to be removed directly.\n",
    "\n",
    "For `PostalCode`, I don't know whether there is any wrong values either. Fortunately this numbers are categorical, the value of number is doesn't matter.\n",
    "\n",
    "I will address 3 columns, `Price`, `Power` and `NumberOfPictures`. I'll use the abnormal detection theory in statistics to calculate the threshold of normal values, i.e. [Q1 - (1.5 * IQR), Q3 + (1.5 * IQR)]. For `NumberOfPictures`, I'll just remove it.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zu_qDnzaWapq",
    "outputId": "ba0f5c80-9e3b-4dd8-c178-786953a1c153"
   },
   "outputs": [],
   "source": [
    "def cal_thresholds(data_array):\n",
    "    q1 = np.percentile(data_array, 25)\n",
    "    q3 = np.percentile(data_array, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_threshold = q1 - 1.5 * iqr\n",
    "    upper_threshold = q3 + 1.5 * iqr\n",
    "    return lower_threshold, upper_threshold\n",
    "\n",
    "lower_price, _ = cal_thresholds(df['Price'])\n",
    "lower_power, upper_power = cal_thresholds(df['Power'])\n",
    "\n",
    "print(lower_price, lower_power, upper_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTUmioT-qx5z"
   },
   "source": [
    "The `lower_price` and `lower_power` are negative, don't make sense. I'll set the threshold manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "DQQJRJBQo1Rl"
   },
   "outputs": [],
   "source": [
    "mask_price = df['Price'] > 100\n",
    "mask_power = (df['Power'] > 40) & (df['Power'] < upper_power)\n",
    "df = df[mask_price & mask_power]\n",
    "df.drop('NumberOfPictures', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "nazRpUL_p0dK",
    "outputId": "f471bc7d-5a92-49fe-a6b3-88ac69cbc164"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWFL9e87D07O"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_j1Q2umJkMj"
   },
   "source": [
    "After data cleaning, the next step should be Feature Engineering which mainly to encode the categorical columns. Since I'll try different models, i.e. linear regression models, tree based models and gradient boost models, therefore I'll apply different encoding methods to fit the requests of training models\n",
    "\n",
    "| Model | Encoding requirements | Accept datetime format| Need scaling |\n",
    "| --    |   -- | -- | -- |\n",
    "| Linear Regression | One-hot Encoding, Features Hashing| No| Yes |\n",
    "| Decision Tree | Label Encoding | Yes | No |\n",
    "| Random Forest | Label Encoding| Yes | No |\n",
    "| LightGBM | No specific requirement| Yes | No |\n",
    "| CatBoost | No specific requirement | Yes | No|\n",
    "| XGBoost | One-hot Encoding | Yes| No |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bnId6-4D066",
    "outputId": "52365f2a-74e9-4797-8097-e1b91a5e977a"
   },
   "outputs": [],
   "source": [
    "categorical = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "for column in categorical:\n",
    "    print(df[column].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MDRpr6TD064"
   },
   "source": [
    "### Linear Regression, XGBoost with One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io97Y0dAD067"
   },
   "source": [
    "##### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwkU4oRID068"
   },
   "source": [
    "The features of `Model` and `Brand` has tens to hundreds unique values, they belong to high cardinality variables, the one-hot encoding is not suitable for them. Other features can be applied the one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a_sF9NJD069"
   },
   "outputs": [],
   "source": [
    "categorical = ['VehicleType', 'Gearbox',  'FuelType', 'NotRepaired']\n",
    "encoded_df = pd.get_dummies(df, columns=categorical)\n",
    "encoded_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m7iE_F9d3SRZ",
    "outputId": "5a090462-7f15-4d34-bde2-02973ece1d98"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60KvzirqD069"
   },
   "source": [
    "##### features hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txm3I-NdD07L"
   },
   "source": [
    "For high caridinality variables, I'll apply the Feature Hash Encoding to convert the categorical data to numeric\n",
    "\n",
    "The number of unique values of `model` is more than 250, I'll set `n_features=500`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyX_XDa_D07L"
   },
   "outputs": [],
   "source": [
    "def feature_hasher(df, column, n_features, prefix):\n",
    "    hasher = FeatureHasher(n_features=n_features, input_type='string')\n",
    "    hashed_features = hasher.transform(df[column].apply(lambda x: list(x)))\n",
    "    hashed_df = pd.DataFrame(hashed_features.toarray())\n",
    "    hashed_df = hashed_df.add_suffix('_' + prefix)\n",
    "    return hashed_df\n",
    "\n",
    "hashed_model_df = feature_hasher(encoded_df, 'Model', 256, 'hashed_model')\n",
    "hashed_brand_df = feature_hasher(encoded_df, 'Brand', 64, 'hashed_brand')\n",
    "encoded_df = pd.concat([encoded_df, hashed_model_df, hashed_brand_df], axis=1) #, hashed_brand_df\n",
    "drop_list = ['Model', 'Brand']\n",
    "encoded_df.drop(drop_list, axis=1, inplace=True)\n",
    "ohe_df = encoded_df.copy() # for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyb4ydsbIZhu"
   },
   "source": [
    "#### Convert datetime to float\n",
    "\n",
    "I need to convert datetime to float in order to feed to Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNrhvjUfIep4"
   },
   "outputs": [],
   "source": [
    "# Convert the datetime to float, otherwise it'll be error during training with LR model\n",
    "encoded_df[\"RegistrationDate\"] = encoded_df['RegistrationDate'].values.astype(float) / 1e9 / 86400 # only keep year, month and day information, get rid of nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XFZJxxciD07N"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "#### Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mC_MzrREevrW"
   },
   "source": [
    "##### Prepare training and testing set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Q85nLB4fBbg"
   },
   "outputs": [],
   "source": [
    "def train_test_prepare(df, target, test_size):\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUrT-gyCegIk"
   },
   "source": [
    "##### Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqOwoXO3d8gd"
   },
   "outputs": [],
   "source": [
    "def standard_scaling(X_train, X_val):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train.loc[:, :] = scaler.transform(X_train.loc[:, :])\n",
    "    X_val.loc[:, :] = scaler.transform(X_val.loc[:, :])\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyzbo9hPCPUb"
   },
   "source": [
    "##### Training and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvccIphOClLY"
   },
   "outputs": [],
   "source": [
    "model_list = []\n",
    "training_time_list = []\n",
    "predict_time_list = []\n",
    "rmse_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNFoZeNgComK"
   },
   "outputs": [],
   "source": [
    "def train_pipeline(X_train,X_val, y_train, y_val, model_name, model_obj, scaling=False, lightGBM_params={}):\n",
    "    start = time.time()\n",
    "    if scaling is True:\n",
    "        X_train, X_val = standard_scaling(X_train, X_val)\n",
    "    if model_name == 'LightGBM' or model_name == 'Optimized LightGBM':\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        model = lgb.train(lightGBM_params, train_data)\n",
    "    elif model_name == 'CatBoost' or model_name == 'Optimized CatBoost':\n",
    "        model = model_obj\n",
    "        model.fit(X_train, y_train, verbose=250)\n",
    "    else:\n",
    "        model = model_obj\n",
    "        model.fit(X_train, y_train)\n",
    "    time_cost = round((time.time() - start), 3)\n",
    "    training_time_list.append(time_cost) # seperate training and predict time\n",
    "    predict_start = time.time()\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False) # squared: If True returns MSE value, if False returns RMSE value.\n",
    "    time_cost = round((time.time() - predict_start), 3)\n",
    "    print(f\"The RMSE of {model_name} with default setting is: {rmse}\")\n",
    "    model_list.append(model_name)\n",
    "    predict_time_list.append(time_cost)\n",
    "    rmse_list.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9AIhL9oJYBd"
   },
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkYpuV0mD07O",
    "outputId": "f71cff85-8afc-43de-c215-f86ceb793f87"
   },
   "outputs": [],
   "source": [
    "X_train_ohe, y_train_ohe, X_val_ohe, y_val_ohe, X_test_ohe, y_test_ohe = train_test_prepare(encoded_df, 'Price', 0.3)\n",
    "train_pipeline(X_train_ohe, X_val_ohe, y_train_ohe, y_val_ohe, \"Linear Regression\", LinearRegression(), scaling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzPArEVEKqjB"
   },
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZDVKUgDKqe3",
    "outputId": "b0766ff7-31e9-4094-fe13-86c9226e47ac"
   },
   "outputs": [],
   "source": [
    "train_pipeline(X_train_ohe, X_val_ohe, y_train_ohe, y_val_ohe, \"XGBoost with default setting\", xgb.XGBRegressor(use_label_encoder=False, random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nedF0nXNDcw"
   },
   "source": [
    "Delete the encoded data to free the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1vXU5fnOCq6"
   },
   "outputs": [],
   "source": [
    "del encoded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWgqkFRjs7n3"
   },
   "source": [
    "### Random Forest, LightGBM, CatBoost with label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw75OCNVigB6"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UBT8gQ9kifBs",
    "outputId": "4a3541be-8394-4f11-b8c2-932bcde5358f"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "label_encoder = OrdinalEncoder()\n",
    "label_encoded_data = label_encoder.fit_transform(df[categorical])\n",
    "reset_index_df = df.reset_index(drop=True).copy()\n",
    "label_encoded_df = pd.concat([reset_index_df.drop(columns=categorical), pd.DataFrame(label_encoded_data, columns=categorical)], axis=1)\n",
    "label_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "l4AiEHH3qqT3"
   },
   "outputs": [],
   "source": [
    "label_encoded_df[\"RegistrationDate\"] = pd.to_datetime(label_encoded_df['RegistrationDate']).values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEY2mWWmt7du"
   },
   "source": [
    "Random Forest with default setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVwh89C3Qy8e",
    "outputId": "a083e4f5-f249-4782-f7a2-2eac23586bdc"
   },
   "outputs": [],
   "source": [
    "X_train_label, y_train_label, X_val_label, y_val_label, X_test_label, y_test_label = train_test_prepare(label_encoded_df, 'Price', 0.3)\n",
    "train_pipeline(X_train_label, X_val_label, y_train_label, y_val_label, \"Random Forest\", RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjMOeWmet_GB"
   },
   "source": [
    "Fine tuning with random search method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g50ZCNy8L2rg"
   },
   "source": [
    "Note: The random search process will take more than 1 hour, I'll comment this code and assign the learned parameter directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hn7y6oL4RjE"
   },
   "outputs": [],
   "source": [
    "def random_optimize(estimator, param_grid, X_train, y_train, n_iter, cv):\n",
    "    random_search = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=n_iter, cv=cv)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"Best parameters: \", random_search.best_params_)\n",
    "    print(\"Best score: \", random_search.best_score_)\n",
    "    return random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJhJ5Jagu0_Y",
    "outputId": "f57b5bb0-82bd-467b-9cfa-7dc6b85191ca"
   },
   "outputs": [],
   "source": [
    "# param_grid_rfr = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 4, 8],\n",
    "#     'min_samples_leaf': [1, 2, 4, 8]\n",
    "# }\n",
    "# best_params = random_optimize(RandomForestRegressor(random_state=42), param_grid_rfr, X_train_label, y_train_label, n_iter=10, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1HBWzCVSWb-",
    "outputId": "dded46a7-9db2-45df-c5ec-3398218cdb28"
   },
   "outputs": [],
   "source": [
    "#best_params = random_search_rfr.best_params_\n",
    "best_params = {'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_depth': None}\n",
    "train_pipeline(X_train_label, X_val_label, y_train_label, y_val_label, \"Random Forest with optimized parameters\", RandomForestRegressor(random_state=42, **best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13q-LfGuDcy4"
   },
   "source": [
    "After fine tuning, I got a slightly better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0gxbOymDeq4"
   },
   "source": [
    "LightGBM with default setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC3BU-TWJrkF"
   },
   "source": [
    "According to the LightGBM document, it can use categorical features directly. But they should be convert to numeric data. So I'll use the dataset which was label encoded for the tree based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JcsmBT9U9wK3",
    "outputId": "7e5006c5-bb7d-42f1-8000-93bda8ef1c02"
   },
   "outputs": [],
   "source": [
    "train_pipeline(X_train_label, X_val_label, y_train_label, y_val_label, \"LightGBM\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKJxCrEuRE30"
   },
   "source": [
    "Fine tuning. I'll use the Optuna, a popular hyperparameter optimization framework, to search the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBTSpVrlRW4_",
    "outputId": "a523b227-f4ff-4a77-d327-1d270fda1087"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "    }\n",
    "    train_data = lgb.Dataset(X_train_label, label=y_train_label)\n",
    "    model = lgb.train(params, train_data)\n",
    "    y_pred_label = model.predict(X_val_label)\n",
    "    rmse = mean_squared_error(y_val_label, y_pred_label)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "best_params_lightGBM = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params_lightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTw1fuILB9CU",
    "outputId": "4365cebb-6220-447a-f8e3-e65c9053b234"
   },
   "outputs": [],
   "source": [
    "train_pipeline(X_train_label, X_val_label, y_train_label, y_val_label, \"Optimized LightGBM\", None, lightGBM_params=best_params_lightGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOQqGr1LTGqP"
   },
   "source": [
    "The RMSE has optimized 5.5% after 10 trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3-OkmVWTrCh"
   },
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfwJGOAiUbzu"
   },
   "source": [
    "#### Default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SECWhTqICTIJ",
    "outputId": "b202ca2b-f2a8-4115-b698-05cc47eb8fb9"
   },
   "outputs": [],
   "source": [
    "train_pipeline(X_train_label, X_val_label, y_train_label, y_val_label, \"CatBoost\", CatBoostRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfcFnuFHVkbF"
   },
   "source": [
    "I'll still use `optuna` to fine tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6oVVRvVVpAV",
    "outputId": "e769ffe0-4b74-4df1-c0c5-0db11fca9cce"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'iterations': 100,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-8, 100),\n",
    "    }\n",
    "\n",
    "    # Create and train the CatBoost model with current hyperparameters\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train_label, y_train_label, verbose=False)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred_label = model.predict(X_val_label)\n",
    "\n",
    "    # Calculate the Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_val_label, y_pred_label)\n",
    "\n",
    "    return mse\n",
    "\n",
    "# Optimize hyperparameters using Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_cat = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOJWGdiQFIWp",
    "outputId": "ad29e43b-db95-4958-9adc-c0ca101a43c1"
   },
   "outputs": [],
   "source": [
    "train_pipeline(X_train_label, X_val_label, y_train_label, y_val_label, \"Optimized CatBoost\", CatBoostRegressor(**best_params_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1E3KfksD07U"
   },
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "bQgVGB2VD07V",
    "outputId": "d5400896-f44f-4457-b7b0-fa49336a31f5"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': model_list, 'RMSE': rmse_list, 'Training Time Cost (second)': training_time_list, 'Predict Time Cost (second)': predict_time_list})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD44Nna5XBZf"
   },
   "source": [
    "Based on the \"results\" table, we can analyze the different models from both the quality and speed perspectives:\n",
    "\n",
    "* Quality Analysis:\n",
    "\n",
    "1. **Linear Regression**: The model has the highest Root Mean Squared Error (RMSE) of 2638.29, indicating that its predictive accuracy is sanity check.\n",
    "2. Other models except the `Optimized CatBoost` obtain the metrics between 1500 to 1600. The worst among them is `LightGBM` with RMSE is 1591.93, the best among them is `CatBoost` with RMSE is 1516.50.\n",
    "3. **Optimized CatBoost**: The optimized CatBoost model further improves its performance, achieving an RMSE of 1472.95, making it the best-performing model among all the listed models.\n",
    "\n",
    "* Speed Analysis:\n",
    "\n",
    "    I seperated the prediction time out from the training time.\n",
    "\n",
    "    For training time, there are 3 hierarchies. `XGBoost` and the Random Forest models take the longest training duration. `Linear Regression` and the CatBoost models lie in the middle with tens seconds. LightGBM models are super fast, it only takes 2 - 3 seconds to train 3000000 entries data.\n",
    "\n",
    "    For prediction time, all models except Random Forest only take less than 1 second. The fastest model is `CatBoost` with default settings, it only takes 0.06 second. The `Optimized CatBoost` and `Linear Regression` are slightly slower with 0.177 second. `XGBoost` and LightGBM take 0.2 - 0.4 second.\n",
    "\n",
    "In summary, the `CatBoost` and `Optimized CatBoost` model achieves both the best quality and speed among all models. `CatBoost` takes 1/3 prediction time of `Optimized CatBoost`, while its RMSE is 3% worse than `Optimized CatBoost`. Alternatively, if a computation time of less than 0.2 second is acceptable, then the `Optimized CatBoost` can be chosen as it offers the highest accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5XwJt_E2Edq"
   },
   "source": [
    "### Evaluate final model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrZCzQ20zmIQ",
    "outputId": "89874f79-0123-4953-a35b-ae757b0b30c4"
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor()\n",
    "model.fit(X_train_label, y_train_label, verbose=250)\n",
    "y_pred = model.predict(X_test_label)\n",
    "rmse = mean_squared_error(y_test_label, y_pred, squared=False) # squared: If True returns MSE value, if False returns RMSE value.\n",
    "print(f\"The RMSE of final model with fine-tuning setting is: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIjtIWbuGzhS"
   },
   "source": [
    "Finally, I applied the `CatBoost` with default settings on the test set and obtain the RMSE of 1520.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Updated\n",
    "\n",
    "1. I've used the training, validation and test sets for training and ev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtG8_BIQD07W"
   },
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRKd8iCKD07W"
   },
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zm_pfiB_D07X"
   },
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [x]  Code is error free\n",
    "- [x]  The cells with the code have been arranged in order of execution\n",
    "- [x]  The data has been downloaded and prepared\n",
    "- [x]  The models have been trained\n",
    "- [x]  The analysis of speed and quality of the models has been performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpAZcUslD07X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NErYalipD058"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "372.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
